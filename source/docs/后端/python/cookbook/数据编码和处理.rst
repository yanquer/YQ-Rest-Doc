=====================
数据编码和处理
=====================


.. post:: 2023-02-20 22:06:49
  :tags: python, cookbook
  :category: 后端
  :author: YanQue
  :location: CD
  :language: zh-cn


主要讨论使用 Python 处理各种不同方式编码的数据，比如 CSV 文件， JSON，XML 和二进制包装记录。
不讨论特殊的算 法问题，而是关注于怎样获取和存储这些格式的数据。

读写 CSV 数据
=====================

对于大多数的 CSV 格式的数据读写问题，都可以使用 csv 库。例如:假设你在一 个名叫 stocks.csv 文件中有一些股票市场数据，就像这样::

  Symbol,Price,Date,Time,Change,Volume
  "AA",39.48,"6/11/2007","9:36am",-0.18,181800
  "AIG",71.38,"6/11/2007","9:36am",-0.15,195500
  "AXP",62.58,"6/11/2007","9:36am",-0.46,935000
  "BA",98.31,"6/11/2007","9:36am",+0.12,104800
  "C",53.08,"6/11/2007","9:36am",-0.25,360900
  "CAT",78.29,"6/11/2007","9:36am",-0.23,225400

如何将这些数据读取为一个元组的序列::

  import csv
  with open('stocks.csv') as f:
    f_csv = csv.reader(f)
    headers = next(f_csv)
    for row in f_csv:
      # Process row
      ...

在上面的代码中，row 会是一个列表。因此，为了访问某个字段，你需要使用下标， 如 row[0] 访问 Symbol，row[4] 访问 Change。
由于这种下标访问通常会引起混淆，你可以考虑使用命名元组。例如::

  from collections import namedtuple
  with open('stock.csv') as f:
    f_csv = csv.reader(f)
    headings = next(f_csv)
    Row = namedtuple('Row', headings)
    for r in f_csv:
      row = Row(*r)
      # Process row
      ...

它允许你使用列名如 row.Symbol 和 row.Change 代替下标访问。
需要注意的是这 个只有在列名是合法的 Python 标识符的时候才生效。
如果不是的话，你可能需要修改 下原始的列名 (如将非标识符字符替换成下划线之类的)。

另外一个选择就是将数据读取到一个字典序列中去。可以这样做::

  import csv
  with open('stocks.csv') as f:
    f_csv = csv.DictReader(f)
    for row in f_csv:
      # process row
      ...

在这个版本中，你可以使用列名去访问每一行的数据了。比如，row['Symbol'] 或 者 row['Change']

为了写入 CSV 数据，你仍然可以使用 csv 模块，不过这时候先创建一个 writer 对象::

  headers = ['Symbol','Price','Date','Time','Change','Volume']
  rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800),
          ('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500),
          ('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000),
        ]
  with open('stocks.csv','w') as f:
    f_csv = csv.writer(f)
    f_csv.writerow(headers)
    f_csv.writerows(rows)

如果你有一个字典序列的数据，可以像这样做::

  headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']
  rows = [{'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007',
          'Time':'9:36am', 'Change':-0.18, 'Volume':181800},
          {'Symbol':'AIG', 'Price': 71.38, 'Date':'6/11/2007',
          'Time':'9:36am', 'Change':-0.15, 'Volume': 195500},
          {'Symbol':'AXP', 'Price': 62.58, 'Date':'6/11/2007',
          'Time':'9:36am', 'Change':-0.46, 'Volume': 935000},
          ]

  with open('stocks.csv','w') as f:
    f_csv = csv.DictWriter(f, headers)
    f_csv.writeheader()
    f_csv.writerows(rows)

你应该总是优先选择 csv 模块分割或解析 CSV 数据。例如，你可能会像编写类似 下面这样的代码::

  with open('stocks.csv') as f:
    for line in f:
      row = line.split(',')
      # process row
      ...

使用这种方式的一个缺点就是你仍然需要去处理一些棘手的细节问题。
比如，如果 某些字段值被引号包围，你不得不去除这些引号。
另外，如果一个被引号包围的字段碰 巧含有一个逗号，那么程序就会因为产生一个错误大小的行而出错。

默认情况下，csv 库可识别 Microsoft Excel 所使用的 CSV 编码规则。这或许也是 最常见的形式，并且也会给你带来最好的兼容性。
然而，如果你查看 csv 的文档，就会 发现有很多种方法将它应用到其他编码格式上 (如修改分割字符等)。
例如，如果你想 读取以 tab 分割的数据，可以这样做::

  # Example of reading tab-separated values
  with open('stock.tsv') as f:
    f_tsv = csv.reader(f, delimiter='\t')
    for row in f_tsv:
      # Process row
      ...

如果你正在读取 CSV 数据并将它们转换为命名元组，需要注意对列名进行合法性 认证。
例如，一个 CSV 格式文件有一个包含非法标识符的列头行，类似下面这样::

  Street Address,Num-Premises,Latitude,Longitude 5412 N CLARK,10,41.980262,-87.668452

这样最终会导致在创建一个命名元组时产生一个 ValueError 异常而失败。为了解 决这问题，你可能不得不先去修正列标题。
例如，可以像下面这样在非法标识符上使用 一个正则表达式替换::

  import re
  with open('stock.csv') as f:
    f_csv = csv.reader(f)
    headers = [ re.sub('[^a-zA-Z_]', '_', h) for h in next(f_csv) ]
    Row = namedtuple('Row', headers)
    for r in f_csv:
      row = Row(*r)
      # Process row
      ...

还有重要的一点需要强调的是，csv 产生的数据都是字符串类型的，它不会做任何 其他类型的转换。
如果你需要做这样的类型转换，你必须自己手动去实现。
下面是一个 在 CSV 数据上执行其他类型转换的例子::

  col_types = [str, float, str, str, float, int]
  with open('stocks.csv') as f:
    f_csv = csv.reader(f)
    headers = next(f_csv)
    for row in f_csv:
      # Apply conversions to the row items
      row = tuple(convert(value) for convert, value in zip(col_types, row))
      ...

另外，下面是一个转换字典中特定字段的例子::

  print('Reading as dicts with type conversion')
  field_types = [ ('Price', float),
                  ('Change', float),
                  ('Volume', int) ]
  with open('stocks.csv') as f:
    for row in csv.DictReader(f):
      row.update((key, conversion(row[key]))
                for key, conversion in field_types)
      print(row)

通常来讲，你可能并不想过多去考虑这些转换问题。
在实际情况中，CSV 文件都 或多或少有些缺失的数据，被破坏的数据以及其它一些让转换失败的问题。
因此，除非 你的数据确实有保障是准确无误的，否则你必须考虑这些问题 (你可能需要增加合适的 错误处理机制)。

最后，如果你读取 CSV 数据的目的是做数据分析和统计的话，你可能需要看一看 Pandas 包。
Pandas 包含了一个非常方便的函数叫 pandas.read_csv() ，它可以加载 CSV 数据到一个 DataFrame 对象中去。
然后利用这个对象你就可以生成各种形式的统 计、过滤数据以及执行其他高级操作了。

读写 JSON 数据
=====================

读写 JSON(JavaScript Object Notation) 编码格式的数据。

json 模块提供了一种很简单的方式来编码和解码 JSON 数据。
其中两个主要的函 数是 json.dumps() 和 json.loads() ，要比其他序列化函数库如 pickle 的接口少得多。
下面演示如何将一个 Python 数据结构转换为 JSON::

  import json
  data = {
      'name' : 'ACME',
      'shares' : 100,
      'price' : 542.23
  }

  json_str = json.dumps(data)

将一个 JSON 编码的字符串转换回一个 Python 数据结构::

  data = json.loads(json_str)

如果你要处理的是文件而不是字符串，你可以使用 json.dump() 和 json.load() 来编码和解码 JSON 数据

JSON 编码支持的基本数据类型为 None ，bool ，int ，float 和 str ，
以及包含 这些类型数据的 lists，tuples 和 dictionaries。
对于 dictionaries，keys 需要是字符串类 型 (字典中任何非字符串类型的 key 在编码时会先转换为字符串)。
为了遵循 JSON 规 范，你应该只编码 Python 的 lists 和 dictionaries。
而且，在 web 应用程序中，顶层对 象被编码为一个字典是一个标准做法。

JSON 编码的格式对于 Python 语法而已几乎是完全一样的，除了一些小的差异之 外。
比如，True 会被映射为 true，False 被映射为 false，而 None 会被映射为 null。
下 面是一个例子，演示了编码后的字符串效果::

  >>> json.dumps(False)
  'false'
  >>> d = {'a': True,
  ...       'b': 'Hello',
  ...       'c': None}
  >>> json.dumps(d)
  '{"b": "Hello", "c": null, "a": true}'
  >>>

如果你试着去检查 JSON 解码后的数据，你通常很难通过简单的打印来确定它 的结构，
特别是当数据的嵌套结构层次很深或者包含大量的字段时。
为了解决这个问 题，可以考虑使用 pprint 模块的 pprint() 函数来代替普通的 print() 函数。
它会按 照 key 的字母顺序并以一种更加美观的方式输出。
下面是一个演示如何漂亮的打印输 出 Twitter 上搜索结果的例子:

  >>> from urllib.request import urlopen
  >>> import json
  >>> u = urlopen('http://search.twitter.com/search.json?q=python&rpp=5')
  >>> resp = json.loads(u.read().decode('utf-8'))

  >>> from pprint import pprint
  >>> pprint(resp)
  {'completed_in': 0.074,
  'max_id': 264043230692245504,
  'max_id_str': '264043230692245504',
  'next_page': '?page=2&max_id=264043230692245504&q=python&rpp=5', 'page': 1,
  'query': 'python',
  'refresh_url': '?since_id=264043230692245504&q=python',
  'results': [{'created_at': 'Thu, 01 Nov 2012 16:36:26 +0000',
              'from_user': ...
              },
              {'created_at': 'Thu, 01 Nov 2012 16:36:14 +0000',
              'from_user': ...
              },
              {'created_at': 'Thu, 01 Nov 2012 16:36:13 +0000',
              'from_user': ...
              },
              {'created_at': 'Thu, 01 Nov 2012 16:36:07 +0000',
              'from_user': ...
              }
              {'created_at': 'Thu, 01 Nov 2012 16:36:04 +0000',
              'from_user': ...
              }],
  'results_per_page': 5,
  'since_id': 0,
  'since_id_str': '0'}
  >>>

一般来讲，JSON 解码会根据提供的数据创建 dicts 或 lists。
如果你想要创建其他 类型的对象，可以给 json.loads() 传递 object_pairs_hook 或 object_hook 参数。
例 如，下面是演示如何解码 JSON 数据并在一个 OrderedDict 中保留其顺序的例子::

  >>> s = '{"name": "ACME", "shares": 50, "price": 490.1}'
  >>> from collections import OrderedDict
  >>> data = json.loads(s, object_pairs_hook=OrderedDict)
  >>> data
  OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])
  >>>

下面是如何将一个 JSON 字典转换为一个 Python 对象例子::

  >>> class JSONObject:
  ...   def __init__(self, d):
  ...     self.__dict__ = d
  ...

  >>>
  >>> data = json.loads(s, object_hook=JSONObject)
  >>> data.name
  'ACME'
  >>> data.shares
  50
  >>> data.price
  490.1
  >>>

JSON 解码后的字典作为一个单个参数传递给 ``__init__()`` 。
然 后，你就可以随心所欲的使用它了，比如作为一个实例字典来直接使用它。

如果你想获得漂亮的格式化字符串 后输出，可以使用 json.dumps() 的 indent 参数。

对象实例通常并不是 JSON 可序列化的。
如果你想序列化对象实例，你可以提供一个函数，它的输入是一个实例，返回一个 可序列化的字典。例如::

  def serialize_instance(obj):
    d = { '__classname__' : type(obj).__name__ }
    d.update(vars(obj))
    return d

如果你想反过来获取这个实例，可以这样做::

  # Dictionary mapping names to known classes
  classes = {
      'Point' : Point
  }

  def unserialize_object(d):
    clsname = d.pop('__classname__', None)
    if clsname:
      cls = classes[clsname]
      obj = cls.__new__(cls) # Make instance without calling __init__
      for key, value in d.items():
        setattr(obj, key, value)
      return obj
    else:
      return d

如何使用这些函数::

  >>> p = Point(2,3)
  >>> s = json.dumps(p, default=serialize_instance)
  >>> s
  '{"__classname__": "Point", "y": 3, "x": 2}'
  >>> a = json.loads(s, object_hook=unserialize_object)
  >>> a
  <__main__.Point object at 0x1017577d0>
  >>> a.x
  2
  >>> a.y
  3
  >>>

解析简单的 XML 数据
=====================

可以使用 xml.etree.ElementTree 模块从简单的 XML 文档中提取数据。
为了演 示，假设你想解析 Planet Python 上的 RSS 源。下面是相应的代码::

  from urllib.request import urlopen
  from xml.etree.ElementTree import parse

  # Download the RSS feed and parse it
  u = urlopen('http://planet.python.org/rss20.xml')
  doc = parse(u)

  # Extract and output tags of interest
  for item in doc.iterfind('channel/item'):
    title = item.findtext('title')
    date = item.findtext('pubDate')
    link = item.findtext('link')

    print(title)
    print(date)
    print(link)
    print()

xml.etree.ElementTree.parse() 函数解析整个 XML 文档并将其转换成一个文 档对象。
然后，你就能使用 find() 、iterfind() 和 findtext() 等方法来搜索特定的 XML 元素了。
这些函数的参数就是某个指定的标签名，

例如 channel/item 或 title 。

- channel/item 表示 <channel> 标签下的 <item> 标签
- title 表示 <title> 标签

ElementTree 模块中的每个元素有一些重要的属性和方法，在解析的时候非常有 用。
tag 属性包含了标签的名字，text 属性包含了内部的文本，而 get() 方法能获取 属性值。例如::

  >>> doc
  <xml.etree.ElementTree.ElementTree object at 0x101339510>
  >>> e = doc.find('channel/title')
  >>> e
  <Element 'title' at 0x10135b310>
  >>> e.tag
  'title'
  >>> e.text
  'Planet Python'
  >>> e.get('some_attribute')
  >>>

有一点要强调的是 xml.etree.ElementTree 并不是 XML 解析的唯一方法。
对于 更高级的应用程序，你需要考虑使用 lxml 。
它使用了和 ElementTree 同样的编程接 口，因此上面的例子同样也适用于 lxml。
你只需要将刚开始的 import 语句换成 from lxml.etree import parse 就行了。
lxml 完全遵循 XML 标准，并且速度也非常快，同 时还支持验证，XSLT，和 XPath 等特性。

增量式解析大型 XML 文件
==========================================

用尽可能少的内存从一个超大的 XML 文档中提取数据

任何时候只要你遇到增量式的数据处理时，第一时间就应该想到迭代器和生成器。
下面是一个很简单的函数，只使用很少的内存就能增量式的处理一个大型 XML 文件::

  def parse_and_remove(filename, path):
    path_parts = path.split('/')
    doc = iterparse(filename, ('start', 'end'))
    # Skip the root element
    next(doc)

    tag_stack = []
    elem_stack = []
    for event, elem in doc:
      if event == 'start':
        tag_stack.append(elem.tag)
        elem_stack.append(elem)
      elif event == 'end':
        if tag_stack == path_parts:
          yield elem
          elem_stack[-2].remove(elem)
        try:
          tag_stack.pop()
          elem_stack.pop()
        except IndexError:
          pass

依赖 ElementTree 模块中的两个核心功能。
第一，iterparse() 方 法允许对 XML 文档进行增量操作。
使用时，你需要提供文件名和一个包含下面一种或 多种类型的事件列表:start , end, start-ns 和 end-ns 。
由 iterparse() 创建的迭 代器会产生形如 (event, elem) 的元组，
其中 event 是上述事件列表中的某一个，而 elem 是相应的 XML 元素。例如::

  >>> data = iterparse('potholes.xml',('start','end'))
  >>> next(data)
  ('start', <Element 'response' at 0x100771d60>)
  >>> next(data)
  ('start', <Element 'row' at 0x100771e68>)
  >>> next(data)
  ('start', <Element 'row' at 0x100771fc8>)
  >>> next(data)
  ('start', <Element 'creation_date' at 0x100771f18>)
  >>> next(data)
  ('end', <Element 'creation_date' at 0x100771f18>)
  >>> next(data)
  ('start', <Element 'status' at 0x1006a7f18>)
  >>> next(data)
  ('end', <Element 'status' at 0x1006a7f18>)
  >>>

**start 事件在某个元素第一次被创建并且还没有被插入其他数据 (如子元素) 时被 创建。而 end 事件在某个元素已经完成时被创建.**
尽管没有在例子中演示，start-ns 和 end-ns 事件被用来处理 XML 文档命名空间的声明。

将字典转换为 XML
=====================

使用一个 Python 字典存储数据，并将它转换成 XML 格式。

尽管 xml.etree.ElementTree 库通常用来做解析工作，其实它也可以创建 XML 文档。例如，考虑如下这个函数::

  from xml.etree.ElementTree import Element

  def dict_to_xml(tag, d):
    '''
    Turn a simple dict of key/value pairs into XML
    '''
    elem = Element(tag)
    for key, val in d.items():
        child = Element(key)
        child.text = str(val)
        elem.append(child)
    return elem

使用::

  >>> s = { 'name': 'GOOG', 'shares': 100, 'price':490.1 }
  >>> e = dict_to_xml('stock', s)
  >>> e
  <Element 'stock' at 0x1004b64c8>
  >>>

转换结果是一个 Element 实例。
对于 I/O 操作，使用 xml.etree.ElementTree 中 的 tostring() 函数很容易就能将它转换成一个字节字符串。例如::

  >>> from xml.etree.ElementTree import tostring
  >>> tostring(e)
  b'<stock><price>490.1</price><shares>100</shares><name>GOOG</name></stock>'
  >>>

如果你想给某个元素添加属性值，可以使用 set() 方法::

  >>> e.set('_id','1234')

  >>> tostring(e)
  b'<stock _id="1234"><price>490.1</price><shares>100</shares><name>GOOG</name> </stock>'
  >>>

如果你还想保持元素的顺序，可以考虑构造一个 OrderedDict 来代替一个普通的 字典.

当创建 XML 的时候，你被限制只能构造字符串类型的值。

问题是如果你手动的去构造的时候可能会碰到一些麻烦。例如，当字典的值中包含 一些特殊字符的时候会怎样呢?::

  >>> d = { 'name' : '<spam>' }
  >>> # String creation
  >>> dict_to_xml_str('item',d)
  '<item><name><spam></name></item>'
  >>> # Proper XML creation
  >>> e = dict_to_xml('item',d)
  >>> tostring(e)
  b'<item><name>&lt;spam&gt;</name></item>'
  >>>

注意到程序的后面那个例子中，字符‘<’和‘>’被替换成了 &lt; 和 &gt;

下面仅供参考，如果你需要手动去转换这些字符，可以使用 xml.sax.saxutils 中
的 escape() 和 unescape() 函数。例如::

  >>> from xml.sax.saxutils import escape, unescape
  >>> escape('<spam>')
  '&lt;spam&gt;'
  >>> unescape(_)
  '<spam>'
  >>>

解析和修改 XML
=====================

读取一个 XML 文档，对它最一些修改，然后将结果写回 XML 文档。

数据文件 pred.xml::

  <?xml version="1.0"?>
  <stop>
    <id>14791</id>
    <nm>Clark &amp; Balmoral</nm>
    <sri>
      <rt>22</rt>
      <d>North Bound</d>
      <dd>North Bound</dd>
    </sri>
    <cr>22</cr>
    <pre>
      <pt>5 MIN</pt>
      <fd>Howard</fd>
      <v>1378</v>
      <rn>22</rn>
    </pre>
    <pre>
      <pt>15 MIN</pt>
      <fd>Howard</fd>
      <v>1867</v>
      <rn>22</rn>
    </pre>
  </stop>

下面是一个利用 ElementTree 来读取这个文档并对它做一些修改的例子::

  >>> from xml.etree.ElementTree import parse, Element
  >>> doc = parse('pred.xml')
  >>> root = doc.getroot()
  >>> root
  <Element 'stop' at 0x100770cb0>
  >>> # Remove a few elements
  >>> root.remove(root.find('sri'))
  >>> root.remove(root.find('cr'))
  >>> # Insert a new element after <nm>...</nm>
  >>> root.getchildren().index(root.find('nm'))
  1
  >>> e = Element('spam')
  >>> e.text = 'This is a test'
  >>> root.insert(2, e)
  >>> # Write back to a file
  >>> doc.write('newpred.xml', xml_declaration=True)
  >>>

处理结果是一个像下面这样新的 XML 文件::

  <?xml version='1.0' encoding='us-ascii'?>
  <stop>
    <id>14791</id>
    <nm>Clark &amp; Balmoral</nm>
    <spam>This is a test</spam>
    <pre>
      <pt>5 MIN</pt>
      <fd>Howard</fd>
      <v>1378</v>
      <rn>22</rn>
    </pre>
    <pre>
      <pt>15 MIN</pt>
      <fd>Howard</fd>
      <v>1867</v>
      <rn>22</rn>
    </pre>
  </stop>

修改一个 XML 文档结构是很容易的，但是你必须牢记的是所有的修改都是针对
父节点元素，将它作为一个列表来处理。例如，如果你删除某个元素，通过调用父节
点的 remove() 方法从它的直接父节点中删除。如果你插入或增加新的元素，你同样使
用父节点元素的 insert() 和 append() 方法。还能对元素使用索引和切片操作，比如
element[i] 或 element[i:j]

利用命名空间解析 XML 文档
==========================================



与关系型数据库的交互
=====================

在关系型数据库中查询、增加或删除记录

Python 中表示多行数据的标准方式是一个由元组构成的序列::

  stocks = [
    ('GOOG', 100, 490.1),
    ('AAPL', 50, 545.75),
    ('FB', 150, 7.45),
    ('HPQ', 75, 33.2),
  ]

你可以使用 Python 标准库中的 sqlite3::

  >>> import sqlite3
  >>> db = sqlite3.connect('database.db')
  >>>

  >>> c = db.cursor()
  >>> c.execute('create table portfolio (symbol text, shares integer, price␣ , real)')
  <sqlite3.Cursor object at 0x10067a730>
  >>> db.commit()
  >>>

  >>> c.executemany('insert into portfolio values (?,?,?)', stocks)
  <sqlite3.Cursor object at 0x10067a730>
  >>> db.commit()
  >>>

  >>> for row in db.execute('select * from portfolio'):
  ... print(row)
  ...
  ('GOOG', 100, 490.1)
  ('AAPL', 50, 545.75)
  ('FB', 150, 7.45)
  ('HPQ', 75, 33.2)
  >>>

如果你想接受用户输入作为参数来执行查询操作，必须确保你使用下面这样的占
位符 ‘‘?‘‘来进行引用参数::

  >>> min_price = 100
  >>> for row in db.execute('select * from portfolio where price >= ?', (min_price,)):
  ...   print(row)
  ...
  ('GOOG', 100, 490.1)
  ('AAPL', 50, 545.75)
  >>>

在比较低的级别上和数据库交互是非常简单的。你只需提供 SQL 语句并调用相应
的模块就可以更新或提取数据了。

一个难点是数据库中的数据和 Python 类型直接的映射。对于日期类型，通常可以
使用 datetime 模块中的 datetime 实例，或者可能是 time 模块中的系统时间戳。对
于数字类型，特别是使用到小数的金融数据，可以用 decimal 模块中的 Decimal 实例
来表示。不幸的是，对于不同的数据库而言具体映射规则是不一样的，你必须参考相应
的文档。

另外一个更加复杂的问题就是 SQL 语句字符串的构造。你千万不要使用 Python
字符串格式化操作符 (如%) 或者 .format() 方法来创建这样的字符串。如果传递给这
些格式化操作符的值来自于用户的输入，那么你的程序就很有可能遭受 SQL 注入攻击
(参考 http://xkcd.com/327 )。查询语句中的通配符 ? 指示后台数据库使用它自己的字
符串替换机制，这样更加的安全。

不幸的是，不同的数据库后台对于通配符的使用是不一样的。
大部分模块使用 ? 或 %s ，还有其他一些使用了不同的符号，比如:0 或:1 来指示参数。同样的，你还是得
去参考你使用的数据库模块相应的文档。一个数据库模块的 paramstyle 属性包含了参
数引用风格的信息。

对于简单的数据库数据的读写问题，使用数据库 API 通常非常简单。如果你要处
理更加复杂的问题，建议你使用更加高级的接口，比如一个对象关系映射 ORM 所提供
的接口。类似 SQLAlchemy 这样的库允许你使用 Python 类来表示一个数据库表，并且
能在隐藏底层 SQL 的情况下实现各种数据库的操作。

编码和解码十六进制数
=====================

将一个十六进制字符串解码成一个字节字符串或者将一个字节字符串编码成
一个十六进制字符串。

是简单的解码或编码一个十六进制的原始字符串，可以使用　 binascii
模块。例如::

  >>> # Initial byte string
  >>> s = b'hello'
  >>> # Encode as hex
  >>> import binascii
  >>> h = binascii.b2a_hex(s)
  >>> h
  b'68656c6c6f'
  >>> # Decode back to bytes
  >>> binascii.a2b_hex(h)
  b'hello'
  >>>

类似的功能同样可以在 base64 模块中找到。例如::

  >>> import base64
  >>> h = base64.b16encode(s)
  >>> h
  b'68656C6C6F'
  >>> base64.b16decode(h)
  b'hello'
  >>>

大部分情况下，通过使用上述的函数来转换十六进制是很简单的。上面两种技术的
主要不同在于大小写的处理。函数 base64.b16decode() 和 base64.b16encode() 只能
操作大写形式的十六进制字母，而 binascii 模块中的函数大小写都能处理。

在解码十六进制数时，函数 b16decode() 和 a2b_hex() 可以接受字节或 unicode
字符串。但是，unicode 字符串必须仅仅只包含 ASCII 编码的十六进制数。

编码解码 Base64 数据
=====================

使用 Base64 格式解码或编码二进制数据。

base64 模块中有两个函数 b64encode() and b64decode() 可以帮你解决这个问题。
例如::

  >>> # Some byte data
  >>> s = b'hello'
  >>> import base64
  >>> # Encode as Base64
  >>> a = base64.b64encode(s)
  >>> a
  b'aGVsbG8='
  >>> # Decode from Base64
  >>> base64.b64decode(a)
  b'hello'
  >>>

Base64 编码仅仅用于面向字节的数据比如字节字符串和字节数组。此外，编码处
理的输出结果总是一个字节字符串。如果你想混合使用 Base64 编码的数据和 Unicode
文本，你必须添加一个额外的解码步骤。例如::

  >>> a = base64.b64encode(s).decode('ascii')
  >>> a
  'aGVsbG8='
  >>>

读写二进制数组数据
=====================

想读写一个二进制数组的结构化数据到 Python 元组中。

可以使用 struct 模块处理二进制数据。下面是一段示例代码将一个 Python 元组
列表写入一个二进制文件，并使用 struct 将每个元组编码为一个结构体::

  from struct import Struct

  def write_records(records, format, f):
    '''
    Write a sequence of tuples to a binary file of structures.
    '''
    record_struct = Struct(format)
    for r in records:
      f.write(record_struct.pack(*r))

  # Example
  if __name__ == '__main__':
    records = [ (1, 2.3, 4.5),
                (6, 7.8, 9.0),
                (12, 13.4, 56.7) ]
    with open('data.b', 'wb') as f:
    write_records(records, '<idd', f)

读取嵌套和可变长二进制数据
==========================================

需要读取包含嵌套或者可变长记录集合的复杂二进制格式的数据。这些数据可
能包含图片、视频、电子地图文件等。

struct 模块可被用来编码/解码几乎所有类型的二进制的数据结构。为了解释清
楚这种数据，假设你用下面的 Python 数据结构来表示一个组成一系列多边形的点的集
合::

  polys = [
    [ (1.0, 2.5), (3.5, 4.0), (2.5, 1.5) ],
    [ (7.0, 1.2), (5.1, 3.0), (0.5, 7.5), (0.8, 9.0) ],
    [ (3.4, 6.3), (1.2, 0.5), (4.6, 9.2) ],
  ]

...

数据的累加与统计操作
=====================

需要处理一个很大的数据集并需要计算数据总和或其他统计量。

对于任何涉及到统计、时间序列以及其他相关技术的数据分析问题，都可以考虑使
用 Pandas 库: :doc:`/docs/后端/python/python三方库/pandas`
































