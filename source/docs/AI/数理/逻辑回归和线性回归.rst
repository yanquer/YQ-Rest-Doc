==============================
逻辑回归和线性回归
==============================

应用领域：
  线性回归（Linear Regression）
    线性回归用于建立连续型目标变量与一个或多个自变量之间的线性关系。它通常用于预测数值型的输出，如房价预测、销售量预测等。
  逻辑回归（Logistic Regression）
    逻辑回归用于建立自变量与二元分类目标变量之间的关系。它常用于解决分类问题，如判断邮件是否为垃圾邮件、预测用户是否会购买某个产品等。

输出类型：
  线性回归
    线性回归的输出是连续的实数值。可以是任意实数，可以是正数、负数或零。
  逻辑回归
    逻辑回归的输出是概率值，表示属于某个类别的概率。通常使用sigmoid函数将线性组合的结果映射到0到1之间的概率。

模型形式：
  线性回归
    线性回归模型假设自变量与因变量之间存在线性关系。
    模型形式可以表示为::

      Y = b0 + b1X1 + b2X2 + ... + bn*Xn

    其中Y是因变量，X1, X2, ..., Xn是自变量，b0, b1, b2, ..., bn是回归系数。
  逻辑回归
    逻辑回归模型使用了sigmoid函数来建模，将线性组合的结果映射到0到1之间的概率。
    模型形式可以表示为::

      P(Y=1|X) = 1 / (1 + exp(-z))

    其中P(Y=1|X)是属于类别1的概率，z是线性组合的结果。

参数估计：
  线性回归
    线性回归通常使用最小二乘法（Ordinary Least Squares）来估计回归系数。
    目标是最小化观测值与模型预测值之间的平方差。
  逻辑回归：
    逻辑回归使用最大似然估计来估计回归系数。
    目标是最大化观测值的似然函数，即最大化观测值为实际类别的概率。



