==============================
Hadoop
==============================

一个分布式框架，
该框架允许使用简单的编程模型跨计算机集群对大型数据集进行分布式处理。
它旨在从单个服务器扩展到数千台机器，每台机器都提供本地计算和存储。

库本身不用于依靠硬件来提供高可用性，而是被设计用来检测和处理应用程序层的故障，
因此可以在计算机集群的顶部提供高可用性服务，每台计算机都容易出现故障。

核心
==============================

HDFS
  分布式文件系统, 对应Google的 `GFS`
MapReduce
  分布式计算框架, 对应Google的 `MapReduce`
HBASE
  实时分布式数据库, 对应Google的 `BigTable`

HDFS结构
==============================

- NameNode（名称节点）
- DataNode（数据节点）
- Client（客户机）

NameNode
  是Master节点（主节点），可以看作是分布式文件系统中的管理者，
  主要负责管理文件系统的命名空间、集群配置信息和存储块的复制等。
  NameNode会将文件系统的Meta-data存储在内存中，
  这些信息主要包括了文件信息、每一个文件对应的文件块的信息和每一个文件块在DataNode的信息等。
DataNode
  是Slave节点（从节点），是文件存储的基本单元，
  它将Block存储在本地文件系统中，保存了Block的Meta-data，同时周期性地将所有存在的Block信息发送给NameNode。
Client
  切分文件；访问HDFS；与NameNode交互，获得文件位置信息；与DataNode交互，读取和写入数据。

还有一个Block（块）的概念：Block是HDFS中的基本读写单元；
HDFS中的文件都是被切割为block（块）进行存储的；
这些块被复制到多个DataNode中；块的大小（通常为64MB）和复制的块数量在创建文件时由Client决定。

MapReduce
==============================

.. note::

  MapReduce 是面向磁盘的

MapReduce其实是一种编程模型。这个模型的核心步骤主要分两部分：Map（映射）和Reduce（归约）。

当你向MapReduce框架提交一个计算作业时，它会首先把计算作业拆分成若干个Map任务，
然后分配到不同的节点上去执行，每一个Map任务处理输入数据中的一部分，
当Map任务完成后，它会生成一些中间文件，这些中间文件将会作为Reduce任务的输入数据。

Reduce任务的主要目标就是把前面若干个Map的输出汇总到一起并输出。

在MapReduce里，为了完成上面这些过程，需要两个角色：JobTracker和TaskTracker。

JobTracker用于调度和管理其它的TaskTracker。JobTracker可以运行于集群中任一台计算机上。TaskTracker 负责执行任务，必须运行于 DataNode 上。

版本历史
==============================

2011年11月，Hadoop 1.0.0版本正式发布，意味着可以用于商业化。

但是，1.0版本中，存在一些问题：

- 扩展性差，JobTracker负载较重，成为性能瓶颈。
- 可靠性差，NameNode只有一个，万一挂掉，整个系统就会崩溃。
- 仅适用MapReduce一种计算方式。
- 资源管理的效率比较低。

所以，2012年5月，Hadoop推出了 2.0版本 。

2.0版本中，在HDFS之上，增加了YARN（资源管理框架）层。它是一个资源管理模块，为各类应用程序提供资源管理和调度。


参考: `深入浅出大数据：到底什么是Hadoop？ <https://zhuanlan.zhihu.com/p/54994736>`_

